# ğŸ‡»ğŸ‡³ Viet-TurnEdge

**Vietnamese Turn-Taking Prediction using Multimodal Deep Learning**

A research project for predicting turn-taking (turn yield, hold, backchannel) in Vietnamese conversations using a hybrid acoustic-linguistic model.

## ğŸ—ï¸ Architecture

```
Audio â†’ [Mel + F0 + Energy] â†’ Causal TCN â†’ â”
                                            â”œâ†’ GMU Fusion â†’ Classifier â†’ Prediction
Text  â†’ [PhoBERT + HÆ° tá»«] â†’ Linear     â†’ â”˜
```

**Components:**
- **Acoustic Branch:** Causal Dilated TCN (4 layers, ~300ms receptive field)
- **Linguistic Branch:** PhoBERT-base-v2 with Vietnamese discourse marker detection
- **Fusion:** Gated Multimodal Unit (GMU) with learned modality weighting
- **Output:** 3 classes - Turn-Yield, Turn-Hold, Backchannel

## ğŸ“ Project Structure

```
Viet-Turn/
â”œâ”€â”€ configs/           # YAML configurations
â”œâ”€â”€ data/              # Datasets (raw, processed, labels)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/          # Audio processing, labeling
â”‚   â”œâ”€â”€ models/        # TCN, PhoBERT, GMU, full model
â”‚   â”œâ”€â”€ training/      # Trainer, losses, metrics
â”‚   â””â”€â”€ asr/           # PhoWhisper integration
â”œâ”€â”€ scripts/           # Training, evaluation scripts
â”œâ”€â”€ tests/             # Unit tests
â””â”€â”€ notebooks/         # Experiments
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Test Model

```python
from src.models import VietTurnEdge
import torch

model = VietTurnEdge()
audio_features = torch.randn(1, 42, 100)  # (B, features, T)

output = model(audio_features)
print(output['probs'].shape)  # (1, 100, 3)
```

## ğŸ“Š Technology Stack

| Component | Choice |
|-----------|--------|
| ASR | PhoWhisper-base |
| Linguistic | PhoBERT-base-v2 |
| Loss | Focal Loss (Î³=2.0) |
| LLM Labeling | Gemini API |

## ğŸ“„ License

MIT License
