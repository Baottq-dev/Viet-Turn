# ğŸ¯ HÆ°á»›ng dáº«n XÃ¢y dá»±ng Dataset Turn-Taking cho Tiáº¿ng Viá»‡t

## Tá»•ng quan Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CUSTOM DATASET PIPELINE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. THU THáº¬P        2. Xá»¬ LÃ           3. GÃN NHÃƒN        4. CHUáº¨N HÃ“A      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”‚
â”‚                                                                              â”‚
â”‚  YouTube/Podcast â†’ Diarization â†’  LLM Labeling â†’  Train/Val/Test           â”‚
â”‚  (50-100 hours)    + ASR            (Gemini)         Split                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Phase 1: Thu tháº­p dá»¯ liá»‡u (Data Collection)

### Nguá»“n dá»¯ liá»‡u Ä‘á» xuáº¥t

| Nguá»“n | Loáº¡i | Æ¯u Ä‘iá»ƒm | Link |
|-------|------|---------|------|
| **YouTube Interviews** | Video/Audio | Dá»… crawl, nhiá»u chá»§ Ä‘á» | yt-dlp |
| **Vietcetera Podcast** | Audio | Cháº¥t lÆ°á»£ng cao, 2 ngÆ°á»i | Spotify/RSS |
| **Radio VOV** | Audio | Há»™i thoáº¡i tá»± nhiÃªn | Website |

### TiÃªu chÃ­ chá»n video/audio:
- âœ… **2 ngÆ°á»i** nÃ³i chuyá»‡n (tá»‘t nháº¥t)
- âœ… Ã‚m thanh rÃµ rÃ ng, Ã­t nhiá»…u
- âœ… Há»™i thoáº¡i tá»± nhiÃªn (khÃ´ng Ä‘á»c ká»‹ch báº£n)
- âœ… Äá»™ dÃ i 10-60 phÃºt má»—i episode
- âŒ TrÃ¡nh: Äá»c tin tá»©c, thuyáº¿t trÃ¬nh 1 ngÆ°á»i

### Script crawl YouTube:

```bash
# CÃ i Ä‘áº·t
pip install yt-dlp

# Download audio tá»« playlist/channel
yt-dlp --extract-audio --audio-format wav --audio-quality 0 \
    -o "data/raw/youtube/%(title)s.%(ext)s" \
    "https://www.youtube.com/playlist?list=PLxxxxxx"

# Hoáº·c tá»« video Ä‘Æ¡n láº»
yt-dlp -x --audio-format wav "https://www.youtube.com/watch?v=xxxxx"
```

### Má»¥c tiÃªu: 50-100 giá» audio há»™i thoáº¡i

---

## Phase 2: Xá»­ lÃ½ Audio (Processing)

### 2.1 Speaker Diarization (TÃ¡ch ngÆ°á»i nÃ³i)

**Tool:** `pyannote-audio` - SOTA speaker diarization

```python
# CÃ i Ä‘áº·t
pip install pyannote.audio

# Code diarization
from pyannote.audio import Pipeline

# Cáº§n Hugging Face token (miá»…n phÃ­)
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-3.1",
    use_auth_token="YOUR_HF_TOKEN"
)

# Cháº¡y diarization
diarization = pipeline("audio.wav")

# Output: ai nÃ³i lÃºc nÃ o
for turn, _, speaker in diarization.itertracks(yield_label=True):
    print(f"{turn.start:.1f}s - {turn.end:.1f}s: {speaker}")
    # 0.0s - 2.5s: SPEAKER_00
    # 2.7s - 5.1s: SPEAKER_01
    # 5.3s - 8.2s: SPEAKER_00
```

### 2.2 ASR Transcription (Chuyá»ƒn giá»ng nÃ³i thÃ nh text)

**Tool:** `PhoWhisper-base` - SOTA Vietnamese ASR

```python
from transformers import pipeline

asr = pipeline(
    "automatic-speech-recognition",
    model="vinai/PhoWhisper-base",
    chunk_length_s=30,
    return_timestamps=True  # Quan trá»ng!
)

result = asr("audio.wav")

# Output vá»›i timestamps
for chunk in result["chunks"]:
    print(f"{chunk['timestamp'][0]:.1f}s: {chunk['text']}")
    # 0.0s: "Anh Ä‘i Ä‘Ã¢u Ä‘áº¥y nhá»‰"
    # 2.8s: "á»ª anh Ä‘i chá»£ mua Ä‘á»“"
```

### 2.3 Merge Diarization + ASR

```python
def merge_diarization_asr(diarization, asr_result):
    """Káº¿t há»£p ai nÃ³i + nÃ³i gÃ¬"""
    segments = []
    
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        # TÃ¬m text tÆ°Æ¡ng á»©ng vá»›i khoáº£ng thá»i gian nÃ y
        text = ""
        for chunk in asr_result["chunks"]:
            chunk_start = chunk["timestamp"][0]
            chunk_end = chunk["timestamp"][1] or chunk_start + 1
            
            # Náº¿u chunk náº±m trong turn nÃ y
            if chunk_start >= turn.start and chunk_end <= turn.end:
                text += chunk["text"] + " "
        
        segments.append({
            "speaker": speaker,
            "start": turn.start,
            "end": turn.end,
            "text": text.strip()
        })
    
    return segments
```

**Output máº«u:**
```json
[
    {"speaker": "A", "start": 0.0, "end": 2.5, "text": "Anh Ä‘i Ä‘Ã¢u Ä‘áº¥y nhá»‰"},
    {"speaker": "B", "start": 2.7, "end": 5.1, "text": "á»ª anh Ä‘i chá»£ mua Ä‘á»“"},
    {"speaker": "A", "start": 5.3, "end": 8.2, "text": "Váº­y mua giÃºp em Ã­t rau nhÃ©"}
]
```

---

## Phase 3: GÃ¡n nhÃ£n Turn-Taking (LLM Labeling)

### Táº¡i sao dÃ¹ng LLM?

```
TRÆ¯á»šC: GÃ¡n nhÃ£n thá»§ cÃ´ng â†’ Tá»‘n 100+ giá» cho 50h audio
SAU:   LLM-as-Judge      â†’ Tá»± Ä‘á»™ng, chá»‰ cáº§n review 10%
```

### Prompt cho Gemini:

```python
import google.generativeai as genai

PROMPT = """Báº¡n lÃ  chuyÃªn gia ngÃ´n ngá»¯ há»c há»™i thoáº¡i tiáº¿ng Viá»‡t.

PhÃ¢n tÃ­ch Ä‘oáº¡n há»™i thoáº¡i sau vÃ  gÃ¡n nhÃ£n cho Má»–I PHÃT NGÃ”N:

- YIELD: NgÆ°á»i nÃ³i Káº¾T THÃšC, sáºµn sÃ ng nhÆ°á»ng lá»i
  (Dáº¥u hiá»‡u: hÆ° tá»« cuá»‘i cÃ¢u nhÆ° "nhÃ©", "nhá»‰", "Ã ", "háº£", "áº¡", giá»ng Ä‘i xuá»‘ng)

- HOLD: NgÆ°á»i nÃ³i CHÆ¯A XONG, sáº½ tiáº¿p tá»¥c
  (Dáº¥u hiá»‡u: cÃ¢u cÃ²n treo, cÃ³ "mÃ ", "thÃ¬", "lÃ ", "vÃ¬", giá»ng treo)

- BACKCHANNEL: Pháº£n há»“i ngáº¯n KHÃ”NG chiáº¿m lÆ°á»£t
  (VÃ­ dá»¥: "á»«", "vÃ¢ng", "á»", "Ã ", "tháº¿ Ã ", "váº­y háº£")

Há»˜I THOáº I:
{conversation}

Tráº£ vá» JSON:
[
  {{"speaker": "A", "text": "...", "label": "YIELD/HOLD/BACKCHANNEL", "reason": "..."}}
]
"""

def label_conversation(segments):
    conversation = "\n".join([
        f"[{s['speaker']}] ({s['start']:.1f}s): {s['text']}"
        for s in segments
    ])
    
    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content(
        PROMPT.format(conversation=conversation),
        generation_config={"response_mime_type": "application/json"}
    )
    
    return json.loads(response.text)
```

### Quality Control (Kiá»ƒm tra cháº¥t lÆ°á»£ng):

```python
# Sau khi LLM gÃ¡n nhÃ£n, kiá»ƒm tra tá»± Ä‘á»™ng
def validate_labels(labeled_segments):
    issues = []
    
    for seg in labeled_segments:
        text = seg["text"].lower()
        label = seg["label"]
        
        # Rule-based validation
        if label == "YIELD" and any(h in text for h in ["mÃ ", "thÃ¬", "vÃ¬"]):
            issues.append(f"Possible HOLD mislabeled as YIELD: {text}")
        
        if label == "BACKCHANNEL" and len(text.split()) > 5:
            issues.append(f"Long text labeled as BACKCHANNEL: {text}")
    
    return issues
```

---

## Phase 4: Chuáº©n bá»‹ Dataset cuá»‘i cÃ¹ng

### Cáº¥u trÃºc thÆ° má»¥c:

```
data/
â”œâ”€â”€ raw/                          # Audio gá»‘c
â”‚   â””â”€â”€ youtube/
â”‚       â”œâ”€â”€ interview_001.wav
â”‚       â””â”€â”€ interview_002.wav
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ diarization/              # Speaker segments
â”‚   â”‚   â””â”€â”€ interview_001.json
â”‚   â”œâ”€â”€ transcripts/              # ASR output
â”‚   â”‚   â””â”€â”€ interview_001.json
â”‚   â””â”€â”€ labeled/                  # Final labels
â”‚       â””â”€â”€ interview_001.json
â””â”€â”€ final/
    â”œâ”€â”€ train.json                # 80%
    â”œâ”€â”€ val.json                  # 10%
    â””â”€â”€ test.json                 # 10%
```

### Format dá»¯ liá»‡u cuá»‘i:

```json
{
  "audio_file": "interview_001.wav",
  "segments": [
    {
      "start": 0.0,
      "end": 2.5,
      "speaker": "A",
      "text": "Anh Ä‘i Ä‘Ã¢u Ä‘áº¥y nhá»‰",
      "label": "YIELD",
      "audio_features": "processed/features/interview_001_seg_0.pt"
    }
  ]
}
```

---

## TÃ³m táº¯t Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLETE WORKFLOW                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  1. yt-dlp         Download YouTube/Podcast audio                â”‚
â”‚       â†“                                                           â”‚
â”‚  2. pyannote       Speaker diarization (ai nÃ³i lÃºc nÃ o)          â”‚
â”‚       â†“                                                           â”‚
â”‚  3. PhoWhisper     ASR transcription (nÃ³i gÃ¬)                    â”‚
â”‚       â†“                                                           â”‚
â”‚  4. Merge          Káº¿t há»£p speaker + text + timestamp            â”‚
â”‚       â†“                                                           â”‚
â”‚  5. Gemini         LLM gÃ¡n nhÃ£n YIELD/HOLD/BACKCHANNEL           â”‚
â”‚       â†“                                                           â”‚
â”‚  6. Validate       Rule-based QC + human review 10%              â”‚
â”‚       â†“                                                           â”‚
â”‚  7. Split          Train/Val/Test                                 â”‚
â”‚       â†“                                                           â”‚
â”‚  8. Features       TrÃ­ch xuáº¥t Mel + F0 + Energy                  â”‚
â”‚                                                                   â”‚
â”‚  OUTPUT: Dataset sáºµn sÃ ng cho training                           â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Thá»i gian Æ°á»›c tÃ­nh:
| BÆ°á»›c | Thá»i gian (50h audio) |
|------|----------------------|
| Crawl | 2-3 giá» |
| Diarization | ~5 giá» (GPU) |
| ASR | ~3 giá» (GPU) |
| LLM Labeling | ~2 giá» (API) |
| **Tá»•ng** | **~12 giá»** |

---

## YÃªu cáº§u pháº§n cá»©ng/API:

| Resource | Requirement |
|----------|-------------|
| GPU | Recommended (RTX 3060+) |
| HuggingFace Token | Free (cho pyannote) |
| Google API Key | Free tier Ä‘á»§ dÃ¹ng |
| Storage | ~100GB cho 50h audio |
